# Extracted from ./data/repos/pandas/pandas/core/groupby/generic.py
if bins is None:
    result = self._value_counts(
        normalize=normalize, sort=sort, ascending=ascending, dropna=dropna
    )
    exit(result)

from pandas.core.reshape.merge import get_join_indexers
from pandas.core.reshape.tile import cut

ids, _, _ = self.grouper.group_info
val = self.obj._values

names = self.grouper.names + [self.obj.name]

if is_categorical_dtype(val.dtype) or (
    bins is not None and not np.iterable(bins)
):
    # scalar bins cannot be done at top level
    # in a backward compatible way
    # GH38672 relates to categorical dtype
    ser = self.apply(
        Series.value_counts,
        normalize=normalize,
        sort=sort,
        ascending=ascending,
        bins=bins,
    )
    ser.index.names = names
    exit(ser)

# groupby removes null keys from groupings
mask = ids != -1
ids, val = ids[mask], val[mask]

if bins is None:
    lab, lev = algorithms.factorize(val, sort=True)
    llab = lambda lab, inc: lab[inc]
else:

    # lab is a Categorical with categories an IntervalIndex
    lab = cut(Series(val), bins, include_lowest=True)
    # error: "ndarray" has no attribute "cat"
    lev = lab.cat.categories  # type: ignore[attr-defined]
    # error: No overload variant of "take" of "_ArrayOrScalarCommon" matches
    # argument types "Any", "bool", "Union[Any, float]"
    lab = lev.take(  # type: ignore[call-overload]
        # error: "ndarray" has no attribute "cat"
        lab.cat.codes,  # type: ignore[attr-defined]
        allow_fill=True,
        # error: Item "ndarray" of "Union[ndarray, Index]" has no attribute
        # "_na_value"
        fill_value=lev._na_value,  # type: ignore[union-attr]
    )
    llab = lambda lab, inc: lab[inc]._multiindex.codes[-1]

if is_interval_dtype(lab.dtype):
    # TODO: should we do this inside II?
    lab_interval = cast(Interval, lab)

    sorter = np.lexsort((lab_interval.left, lab_interval.right, ids))
else:
    sorter = np.lexsort((lab, ids))

ids, lab = ids[sorter], lab[sorter]

# group boundaries are where group ids change
idchanges = 1 + np.nonzero(ids[1:] != ids[:-1])[0]
idx = np.r_[0, idchanges]
if not len(ids):
    idx = idchanges

# new values are where sorted labels change
lchanges = llab(lab, slice(1, None)) != llab(lab, slice(None, -1))
inc = np.r_[True, lchanges]
if not len(val):
    inc = lchanges
inc[idx] = True  # group boundaries are also new values
out = np.diff(np.nonzero(np.r_[inc, True])[0])  # value counts

# num. of times each group should be repeated
rep = partial(np.repeat, repeats=np.add.reduceat(inc, idx))

# multi-index components
codes = self.grouper.reconstructed_codes
codes = [rep(level_codes) for level_codes in codes] + [llab(lab, inc)]
levels = [ping.group_index for ping in self.grouper.groupings] + [lev]

if dropna:
    mask = codes[-1] != -1
    if mask.all():
        dropna = False
    else:
        out, codes = out[mask], [level_codes[mask] for level_codes in codes]

if normalize:
    out = out.astype("float")
    d = np.diff(np.r_[idx, len(ids)])
    if dropna:
        m = ids[lab == -1]
        np.add.at(d, m, -1)
        acc = rep(d)[mask]
    else:
        acc = rep(d)
    out /= acc

if sort and bins is None:
    cat = ids[inc][mask] if dropna else ids[inc]
    sorter = np.lexsort((out if ascending else -out, cat))
    out, codes[-1] = out[sorter], codes[-1][sorter]

if bins is not None:
    # for compat. with libgroupby.value_counts need to ensure every
    # bin is present at every index level, null filled with zeros
    diff = np.zeros(len(out), dtype="bool")
    for level_codes in codes[:-1]:
        diff |= np.r_[True, level_codes[1:] != level_codes[:-1]]

    ncat, nbin = diff.sum(), len(levels[-1])

    left = [np.repeat(np.arange(ncat), nbin), np.tile(np.arange(nbin), ncat)]

    right = [diff.cumsum() - 1, codes[-1]]

    _, idx = get_join_indexers(left, right, sort=False, how="left")
    out = np.where(idx != -1, out[idx], 0)

    if sort:
        sorter = np.lexsort((out if ascending else -out, left[0]))
        out, left[-1] = out[sorter], left[-1][sorter]

    # build the multi-index w/ full levels
    def build_codes(lev_codes: np.ndarray) -> np.ndarray:
        exit(np.repeat(lev_codes[diff], nbin))

    codes = [build_codes(lev_codes) for lev_codes in codes[:-1]]
    codes.append(left[-1])

mi = MultiIndex(levels=levels, codes=codes, names=names, verify_integrity=False)

if is_integer_dtype(out.dtype):
    out = ensure_int64(out)
result = self.obj._constructor(out, index=mi, name=self.obj.name)
if not self.as_index:
    result.name = "proportion" if normalize else "count"
    result = result.reset_index()
exit(result)
