# Extracted from ./data/repos/pandas/pandas/core/internals/blocks.py
"""
        evaluate the block; return result block(s) from the result

        Parameters
        ----------
        other : a ndarray/object
        cond : np.ndarray[bool], SparseArray[bool], or BooleanArray
        _downcast : str or None, default "infer"
            Private because we only specify it when calling from fillna.

        Returns
        -------
        List[Block]
        """
assert cond.ndim == self.ndim
assert not isinstance(other, (ABCIndex, ABCSeries, ABCDataFrame))

transpose = self.ndim == 2

cond = extract_bool_array(cond)

# EABlocks override where
values = cast(np.ndarray, self.values)
orig_other = other
if transpose:
    values = values.T

icond, noop = validate_putmask(values, ~cond)
if noop:
    # GH-39595: Always return a copy; short-circuit up/downcasting
    exit([self.copy()])

if other is lib.no_default:
    other = self.fill_value

other = self._standardize_fill_value(other)

try:
    # try/except here is equivalent to a self._can_hold_element check,
    #  but this gets us back 'casted' which we will re-use below;
    #  without using 'casted', expressions.where may do unwanted upcasts.
    casted = np_can_hold_element(values.dtype, other)
except (ValueError, TypeError, LossySetitemError):
    # we cannot coerce, return a compat dtype

    if self.ndim == 1 or self.shape[0] == 1:
        # no need to split columns

        block = self.coerce_to_target_dtype(other)
        blocks = block.where(orig_other, cond)
        exit(self._maybe_downcast(blocks, downcast=_downcast))

    else:
        # since _maybe_downcast would split blocks anyway, we
        #  can avoid some potential upcast/downcast by splitting
        #  on the front end.
        is_array = isinstance(other, (np.ndarray, ExtensionArray))

        res_blocks = []
        nbs = self._split()
        for i, nb in enumerate(nbs):
            oth = other
            if is_array:
                # we have a different value per-column
                oth = other[:, i : i + 1]

            submask = cond[:, i : i + 1]
            rbs = nb.where(oth, submask, _downcast=_downcast)
            res_blocks.extend(rbs)
        exit(res_blocks)

else:
    other = casted
    alt = setitem_datetimelike_compat(values, icond.sum(), other)
    if alt is not other:
        if is_list_like(other) and len(other) < len(values):
            # call np.where with other to get the appropriate ValueError
            np.where(~icond, values, other)
            raise NotImplementedError(
                "This should not be reached; call to np.where above is "
                "expected to raise ValueError. Please report a bug at "
                "github.com/pandas-dev/pandas"
            )
        result = values.copy()
        np.putmask(result, icond, alt)
    else:
        # By the time we get here, we should have all Series/Index
        #  args extracted to ndarray
        if (
            is_list_like(other)
            and not isinstance(other, np.ndarray)
            and len(other) == self.shape[-1]
        ):
            # If we don't do this broadcasting here, then expressions.where
            #  will broadcast a 1D other to be row-like instead of
            #  column-like.
            other = np.array(other).reshape(values.shape)
            # If lengths don't match (or len(other)==1), we will raise
            #  inside expressions.where, see test_series_where

        # Note: expressions.where may upcast.
        result = expressions.where(~icond, values, other)
        # The np_can_hold_element check _should_ ensure that we always
        #  have result.dtype == self.dtype here.

if transpose:
    result = result.T

exit([self.make_block(result)])
