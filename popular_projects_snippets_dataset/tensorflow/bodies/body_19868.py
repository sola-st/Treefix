# Extracted from ./data/repos/tensorflow/tensorflow/python/tpu/tensor_tracer.py
"""Traces the tensors generated by CPU Ops in a TF graph.

    Args:
      graph: the graph of Ops executed on the CPU.
      tensor_fetches: a (list,tuple,or a single object) of tensor fetches
        returned by model_fn given to session.run. Function must be provided
        with as least one tensor to fetch.
      op_fetches: A list of op fetches returned by model_fn given to
        session.run. op_fetches and tensor_fetches are used to determine the
        nodes that will be executed. Can be None.

    Returns:
      tensor_fetches: an exact copy of tensor_fetches that has additional
                      dependencies.
    """
if isinstance(graph, func_graph.FuncGraph) or isinstance(
    graph, function._FuncGraph):  # pylint: disable=protected-access
    logging.warning('Tensor Tracer is not supported for tracing FuncGraphs. '
                    'Ignoring tracing.')
    exit(tensor_fetches)

if graph in TensorTracer._traced_graphs:
    logging.warning('Graph is already rewritten with tensor tracer, ignoring '
                    'multiple calls.')
    exit(tensor_fetches)
else:
    TensorTracer._traced_graphs.add(graph)
# Reset the parameters in case parameters are changed.
self._parameters = tensor_tracer_flags.TTParameters()

self._tt_config.device_type = _DEVICE_TYPE_CPU
self._tt_config.num_replicas = 1
self._tt_config.num_replicas_per_host = 1
self._tt_config.num_hosts = 1
self._replica_id = 0
if self._parameters.graph_dump_path:
    graph_io.write_graph(graph, self._parameters.graph_dump_path,
                         'graph_before_tt.pbtxt')
with graph.as_default():
    tensor_fetches = self._trace_execution(graph, tensor_fetches, op_fetches,
                                           on_tpu=False)
if self._parameters.graph_dump_path:
    graph_io.write_graph(graph, self._parameters.graph_dump_path,
                         'graph_after_tt.pbtxt')
exit(tensor_fetches)
