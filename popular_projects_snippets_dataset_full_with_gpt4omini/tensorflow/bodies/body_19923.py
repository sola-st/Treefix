# Extracted from ./data/repos/tensorflow/tensorflow/python/tpu/tpu_embedding_v1.py
if not self._built:
    # This can be called while tracing a function, so we wrap the
    # initialization code with init_scope so it runs eagerly, this means that
    # it will not be included in the function graph generated by tracing so
    # that we can be sure that we only initialize the TPU for embeddings
    # exactly once.
    with ops.init_scope():
        self.build()
