# Extracted from ./data/repos/tensorflow/tensorflow/examples/speech_commands/models.py
"""Builds a standard convolutional model.

  This is roughly the network labeled as 'cnn-trad-fpool3' in the
  'Convolutional Neural Networks for Small-footprint Keyword Spotting' paper:
  http://www.isca-speech.org/archive/interspeech_2015/papers/i15_1478.pdf

  Here's the layout of the graph:

  (fingerprint_input)
          v
      [Conv2D]<-(weights)
          v
      [BiasAdd]<-(bias)
          v
        [Relu]
          v
      [MaxPool]
          v
      [Conv2D]<-(weights)
          v
      [BiasAdd]<-(bias)
          v
        [Relu]
          v
      [MaxPool]
          v
      [MatMul]<-(weights)
          v
      [BiasAdd]<-(bias)
          v

  This produces fairly good quality results, but can involve a large number of
  weight parameters and computations. For a cheaper alternative from the same
  paper with slightly less accuracy, see 'low_latency_conv' below.

  During training, dropout nodes are introduced after each relu, controlled by a
  placeholder.

  Args:
    fingerprint_input: TensorFlow node that will output audio feature vectors.
    model_settings: Dictionary of information about the model.
    is_training: Whether the model is going to be used for training.

  Returns:
    TensorFlow node outputting logits results, and optionally a dropout
    placeholder.
  """
if is_training:
    dropout_rate = tf.compat.v1.placeholder(tf.float32, name='dropout_rate')
input_frequency_size = model_settings['fingerprint_width']
input_time_size = model_settings['spectrogram_length']
fingerprint_4d = tf.reshape(fingerprint_input,
                            [-1, input_time_size, input_frequency_size, 1])
first_filter_width = 8
first_filter_height = 20
first_filter_count = 64
first_weights = tf.compat.v1.get_variable(
    name='first_weights',
    initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.01),
    shape=[first_filter_height, first_filter_width, 1, first_filter_count])
first_bias = tf.compat.v1.get_variable(
    name='first_bias',
    initializer=tf.compat.v1.zeros_initializer,
    shape=[first_filter_count])

first_conv = tf.nn.conv2d(input=fingerprint_4d,
                          filters=first_weights,
                          strides=[1, 1, 1, 1],
                          padding='SAME') + first_bias
first_relu = tf.nn.relu(first_conv)
if is_training:
    first_dropout = tf.nn.dropout(first_relu, rate=dropout_rate)
else:
    first_dropout = first_relu
max_pool = tf.nn.max_pool2d(input=first_dropout,
                            ksize=[1, 2, 2, 1],
                            strides=[1, 2, 2, 1],
                            padding='SAME')
second_filter_width = 4
second_filter_height = 10
second_filter_count = 64
second_weights = tf.compat.v1.get_variable(
    name='second_weights',
    initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.01),
    shape=[
        second_filter_height, second_filter_width, first_filter_count,
        second_filter_count
    ])
second_bias = tf.compat.v1.get_variable(
    name='second_bias',
    initializer=tf.compat.v1.zeros_initializer,
    shape=[second_filter_count])
second_conv = tf.nn.conv2d(input=max_pool,
                           filters=second_weights,
                           strides=[1, 1, 1, 1],
                           padding='SAME') + second_bias
second_relu = tf.nn.relu(second_conv)
if is_training:
    second_dropout = tf.nn.dropout(second_relu, rate=dropout_rate)
else:
    second_dropout = second_relu
second_conv_shape = second_dropout.get_shape()
second_conv_output_width = second_conv_shape[2]
second_conv_output_height = second_conv_shape[1]
second_conv_element_count = int(
    second_conv_output_width * second_conv_output_height *
    second_filter_count)
flattened_second_conv = tf.reshape(second_dropout,
                                   [-1, second_conv_element_count])
label_count = model_settings['label_count']
final_fc_weights = tf.compat.v1.get_variable(
    name='final_fc_weights',
    initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.01),
    shape=[second_conv_element_count, label_count])
final_fc_bias = tf.compat.v1.get_variable(
    name='final_fc_bias',
    initializer=tf.compat.v1.zeros_initializer,
    shape=[label_count])
final_fc = tf.matmul(flattened_second_conv, final_fc_weights) + final_fc_bias
if is_training:
    exit((final_fc, dropout_rate))
else:
    exit(final_fc)
