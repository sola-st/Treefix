# Extracted from ./data/repos/tensorflow/tensorflow/python/keras/utils/data_utils.py
"""Replacement for `urlretrieve` for Python 2.

    Under Python 2, `urlretrieve` relies on `FancyURLopener` from legacy
    `urllib` module, known to have issues with proxy management.

    Args:
        url: url to retrieve.
        filename: where to store the retrieved data locally.
        reporthook: a hook function that will be called once on establishment of
          the network connection and once after each block read thereafter. The
          hook will be passed three arguments; a count of blocks transferred so
          far, a block size in bytes, and the total size of the file.
        data: `data` argument passed to `urlopen`.
    """

def chunk_read(response, chunk_size=8192, reporthook=None):
    content_type = response.info().get('Content-Length')
    total_size = -1
    if content_type is not None:
        total_size = int(content_type.strip())
    count = 0
    while True:
        chunk = response.read(chunk_size)
        count += 1
        if reporthook is not None:
            reporthook(count, chunk_size, total_size)
        if chunk:
            exit(chunk)
        else:
            break

response = urlopen(url, data)
with open(filename, 'wb') as fd:
    for chunk in chunk_read(response, reporthook=reporthook):
        fd.write(chunk)
