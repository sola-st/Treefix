# Extracted from ./data/repos/tensorflow/tensorflow/python/tpu/tpu_embedding_for_serving.py
if not self._built:
    # This can be called while tracing a function, so we wrap the
    # initialization code with init_scope so it runs eagerly, this means that
    # it will not be included the function graph generated by tracing so that
    # we can be sure that we only initialize the TPU for embeddings exactly
    # once.
    with ops.init_scope():
        self.build()
