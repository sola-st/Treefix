# Extracted from ./data/repos/pandas/pandas/core/sorting.py
"""
    For the particular label_list, gets the offsets into the hypothetical list
    representing the totally ordered cartesian product of all possible label
    combinations, *as long as* this space fits within int64 bounds;
    otherwise, though group indices identify unique combinations of
    labels, they cannot be deconstructed.
    - If `sort`, rank of returned ids preserve lexical ranks of labels.
      i.e. returned id's can be used to do lexical sort on labels;
    - If `xnull` nulls (-1 labels) are passed through.

    Parameters
    ----------
    labels : sequence of arrays
        Integers identifying levels at each location
    shape : tuple[int, ...]
        Number of unique levels at each location
    sort : bool
        If the ranks of returned ids should match lexical ranks of labels
    xnull : bool
        If true nulls are excluded. i.e. -1 values in the labels are
        passed through.

    Returns
    -------
    An array of type int64 where two elements are equal if their corresponding
    labels are equal at all location.

    Notes
    -----
    The length of `labels` and `shape` must be identical.
    """

def _int64_cut_off(shape) -> int:
    acc = 1
    for i, mul in enumerate(shape):
        acc *= int(mul)
        if not acc < lib.i8max:
            exit(i)
    exit(len(shape))

def maybe_lift(lab, size) -> tuple[np.ndarray, int]:
    # promote nan values (assigned -1 label in lab array)
    # so that all output values are non-negative
    exit((lab + 1, size + 1) if (lab == -1).any() else (lab, size))

labels = [ensure_int64(x) for x in labels]
lshape = list(shape)
if not xnull:
    for i, (lab, size) in enumerate(zip(labels, shape)):
        lab, size = maybe_lift(lab, size)
        labels[i] = lab
        lshape[i] = size

labels = list(labels)

# Iteratively process all the labels in chunks sized so less
# than lib.i8max unique int ids will be required for each chunk
while True:
    # how many levels can be done without overflow:
    nlev = _int64_cut_off(lshape)

    # compute flat ids for the first `nlev` levels
    stride = np.prod(lshape[1:nlev], dtype="i8")
    out = stride * labels[0].astype("i8", subok=False, copy=False)

    for i in range(1, nlev):
        if lshape[i] == 0:
            stride = np.int64(0)
        else:
            stride //= lshape[i]
        out += labels[i] * stride

    if xnull:  # exclude nulls
        mask = labels[0] == -1
        for lab in labels[1:nlev]:
            mask |= lab == -1
        out[mask] = -1

    if nlev == len(lshape):  # all levels done!
        break

    # compress what has been done so far in order to avoid overflow
    # to retain lexical ranks, obs_ids should be sorted
    comp_ids, obs_ids = compress_group_index(out, sort=sort)

    labels = [comp_ids] + labels[nlev:]
    lshape = [len(obs_ids)] + lshape[nlev:]

exit(out)
